{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7545459",
   "metadata": {},
   "source": [
    "# nd608 - Project Personalized Real Estate Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d4c6b",
   "metadata": {},
   "source": [
    "## Generate Synthetic Real Estate Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd664e8",
   "metadata": {},
   "source": [
    "The purpose of this document is to generate synthetic real estate listings using OpenAI's generative AI APIs. We'll also create a [LanceDB](https://lancedb.com/) attaching embeddings to the generated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3019f9-a6f8-4797-995b-0bd9ef876695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file. Alternatively you can\n",
    "# manually set the value of OPENAI_API_KEY on this cell.\n",
    "\n",
    "from io import BytesIO\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ModuleNotFoundError:\n",
    "    pass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in environ:\n",
    "    environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b20820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from textwrap import dedent\n",
    "\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel, Field, NonNegativeFloat, NonNegativeInt\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa71c1",
   "metadata": {},
   "source": [
    "We'll use [LangChain](https://www.langchain.com/)'s `PromptTemplate`, `PydanticOutputParser` to generate the synthetic real estate listings in a structured format to make it easier to store the information on a table. We'll use the format suggested on the project's instruction:\n",
    "\n",
    "```\n",
    "Neighborhood: Green Oaks\n",
    "Price: $800,000\n",
    "Bedrooms: 3\n",
    "Bathrooms: 2\n",
    "House Size: 2,000 sqft\n",
    "\n",
    "Description: Welcome to this eco-friendly oasis nestled in the heart of Green Oaks. This charming 3-bedroom, 2-bathroom home boasts energy-efficient features such as solar panels and a well-insulated structure. Natural light floods the living spaces, highlighting the beautiful hardwood floors and eco-conscious finishes. The open-concept kitchen and dining area lead to a spacious backyard with a vegetable garden, perfect for the eco-conscious family. Embrace sustainable living without compromising on style in this Green Oaks gem.\n",
    "\n",
    "Neighborhood Description: Green Oaks is a close-knit, environmentally-conscious community with access to organic grocery stores, community gardens, and bike paths. Take a stroll through the nearby Green Oaks Park or grab a cup of coffee at the cozy Green Bean Cafe. With easy access to public transportation and bike lanes, commuting is a breeze.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab091b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealEstateListing(BaseModel):\n",
    "    neighborhood: str = Field(description=\"Name of the neighborhod\")\n",
    "    price: NonNegativeInt = Field(description=\"List price of the property\")\n",
    "    bedrooms: NonNegativeInt = Field(description=\"Number of bedrooms\")\n",
    "    bathrooms: NonNegativeFloat | NonNegativeInt = Field(description=\"Number of bathrooms\")\n",
    "    description: str = Field(description=\"Brief description of the property\")\n",
    "    neighborhood_description: str = Field(description=\"Brief description of the neighborhood\")\n",
    "\n",
    "\n",
    "class RealEstateListingWithImage(RealEstateListing):\n",
    "    image: bytes | None = Field(description=\"Contents of the generated image\", default=None)\n",
    "    image_filename: str = Field(description=\"Filename of the generated image\", default=None)\n",
    "\n",
    "\n",
    "class RealEstateListings(BaseModel):\n",
    "    listings: list[RealEstateListing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=RealEstateListings)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=dedent(\"\"\"\\\n",
    "        You are a writer and a real estate expert with extensive\n",
    "        knowledge of the terminolgy and a capable of writing lengthy,\n",
    "        easy to read and factual descriptions of properties.\n",
    "\n",
    "        Generate {num_listings} listings of imaginary real estate\n",
    "        properties. The description of the property should include detailed\n",
    "        mentions of the property's features like the number of bedrooms and\n",
    "        bathrooms. The description of the property should describe the exterior.\n",
    "        The description of the property should contain at 2 sentences.\n",
    "        Include both upper-middle class and lower income neighborhoods.\n",
    "    \"\"\") + \"\\n{format_instructions}\",\n",
    "    input_variables=[\"request\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42752278",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.format(num_listings=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fd334",
   "metadata": {},
   "source": [
    "We'll use OpenAI's `gpt-4-turbo` model as it has higher chances of following the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f194da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4-turbo\",\n",
    "    temperature=0.2,  # Sacrificing reproducibility to give the model some leeway\n",
    "    max_tokens=4000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = llm.invoke(prompt.format(num_listings=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_model_response = parser.parse(model_response.content)\n",
    "parsed_model_response.listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c2fb4",
   "metadata": {},
   "source": [
    "Let's save the generated real estate listings to avoid hitting the model multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e53404",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80187c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"listings.pickle\", \"wb\") as f:\n",
    "    pickle.dump(parsed_model_response.listings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"listings.pickle\", \"rb\") as f:\n",
    "    listings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9492d7",
   "metadata": {},
   "source": [
    "## Generate Images for the Synthetic Real Estate Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b06742",
   "metadata": {},
   "source": [
    "We want to increase the usability of our recommendation app, so we'll use OpenAI's DALL-e. We're adding specific hints to the prompt to generate photorealistic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a69c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = Path(\"images\")\n",
    "images_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ee2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_image = []\n",
    "\n",
    "for i, listing in enumerate(listings):\n",
    "    display(Markdown(f\"Generating image for listing with description: _'{listing.description}'_....\"))\n",
    "\n",
    "    dalle2_response = client.images.generate(\n",
    "        model=\"dall-e-2\",\n",
    "        prompt=f\"Photo of {listing.description}. 1/100s, ISO 100, Daylight.\",\n",
    "        size=\"512x512\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    image_filename = f\"listing_{i}.jpg\"\n",
    "\n",
    "    with open(images_dir / image_filename, \"wb\") as f:\n",
    "        response = requests.get(dalle2_response.data[0].url)\n",
    "        response.raise_for_status()\n",
    "        f.write(response.content)\n",
    "\n",
    "    listings_with_image.append(\n",
    "        RealEstateListingWithImage(\n",
    "            **listing.model_dump(),\n",
    "            image=response.content,\n",
    "            image_filename=image_filename\n",
    "        )\n",
    "    )\n",
    "\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aca1e",
   "metadata": {},
   "source": [
    "We save the results one more time, to avoid hitting the model multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc084fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"listings_with_image.pickle\", \"wb\") as f:\n",
    "    pickle.dump(listings_with_image, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"listings_with_image.pickle\", \"rb\") as f:\n",
    "    listings_with_image = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23289d",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Listings/Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d55eb57",
   "metadata": {},
   "source": [
    "We're going to use [HuggingFace's CLIP](https://huggingface.co/docs/transformers/model_doc/clip) models to generate embeddings for the listing and image combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = \"openai/clip-vit-large-patch14\"\n",
    "\n",
    "model = CLIPModel.from_pretrained(clip_model)\n",
    "processor = CLIPProcessor.from_pretrained(clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8921205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
